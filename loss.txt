epoch, training loss, validation loss
0  0.900128  0.900128
1  0.172423  0.080835
2  0.048326  0.034984
3  0.031209  0.029629
4  0.027875  0.023725
5  0.025079  0.022116
6  0.022921  0.021264
7  0.021802  0.018007
8  0.020173  0.018575
9  0.018958  0.018362
10  0.018234  0.016097
11  0.014743  0.013571
12  0.014557  0.014245
13  0.014411  0.014732
14  0.014160  0.015124
15  0.013913  0.014970
16  0.013677  0.014752
17  0.013366  0.014580
18  0.013141  0.014282
19  0.012881  0.014226
20  0.012606  0.014113
21  0.011002  0.010258
22  0.010728  0.010088
23  0.010553  0.009911
24  0.010445  0.009797
25  0.010317  0.009703
26  0.010192  0.009607
27  0.010075  0.009498
28  0.009955  0.009398
29  0.009835  0.009322
30  0.009725  0.009219
31  0.009017  0.008596
32  0.008887  0.008542
33  0.008807  0.008485
34  0.008731  0.008394
35  0.008661  0.008305
36  0.008592  0.008225
37  0.008525  0.008156
38  0.008460  0.008079
39  0.008402  0.008012
40  0.008342  0.007952
41  0.007928  0.007967
42  0.007894  0.007971
43  0.007856  0.007954
44  0.007818  0.007935
45  0.007779  0.007909
46  0.007739  0.007889
47  0.007701  0.007863
48  0.007663  0.007824
49  0.007626  0.007794
50  0.007589  0.007761
51  0.007340  0.007218
52  0.007300  0.007194
53  0.007280  0.007172
54  0.007260  0.007151
55  0.007240  0.007130
56  0.007221  0.007109
57  0.007201  0.007088
58  0.007181  0.007068
59  0.007161  0.007046
60  0.007141  0.007027
