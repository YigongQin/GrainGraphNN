epoch, training loss, validation loss
0  1.013966  1.013966
1  0.084999  0.103055
2  0.031205  0.034426
3  0.026647  0.035180
4  0.025589  0.026981
5  0.021549  0.020536
6  0.020839  0.018679
7  0.019087  0.018245
8  0.016276  0.020724
9  0.014926  0.019875
10  0.013865  0.017869
11  0.014396  0.014011
12  0.013969  0.013652
13  0.013514  0.014445
14  0.012760  0.015137
15  0.011940  0.015100
16  0.011332  0.015011
17  0.011092  0.014602
18  0.011007  0.014479
19  0.010630  0.014146
20  0.010443  0.013937
21  0.010061  0.010501
22  0.009736  0.010566
23  0.009698  0.010700
24  0.009686  0.010494
25  0.009597  0.010244
26  0.009327  0.010061
27  0.009212  0.009933
28  0.009004  0.009749
29  0.008887  0.009568
30  0.008690  0.009423
31  0.008569  0.008727
32  0.008514  0.008797
33  0.008535  0.008725
34  0.008474  0.008576
35  0.008387  0.008432
36  0.008317  0.008342
37  0.008248  0.008267
38  0.008186  0.008215
39  0.008110  0.008147
40  0.008061  0.008114
41  0.007556  0.007859
42  0.007521  0.007863
43  0.007513  0.007847
44  0.007514  0.007822
45  0.007473  0.007783
46  0.007462  0.007741
47  0.007430  0.007696
48  0.007414  0.007660
49  0.007398  0.007628
50  0.007365  0.007585
51  0.007134  0.007225
52  0.007090  0.007213
53  0.007052  0.007203
54  0.007040  0.007195
55  0.007023  0.007184
56  0.007001  0.007173
57  0.006986  0.007160
58  0.006963  0.007146
59  0.006947  0.007131
60  0.006926  0.007116
